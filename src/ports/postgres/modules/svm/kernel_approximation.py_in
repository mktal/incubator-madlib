from __future__ import division

import plpy

from utilities.utilities import unique_string
from utilities.utilities import extract_keyvalue_params
from utilities.utilities import num_features

from math import sqrt
from math import pi

from itertools import repeat
from itertools import chain

# TODO: remove it
import numpy as np


def _create_mat(X, tbl_name, temporary=False, row='id', val='val'):
    header = [row, val]
    header_str = ','.join(header)
    header_with_type_str = ','.join([row + ' integer',
                                    val + ' float[]'])
    temp_str = '' if not temporary else 'TEMP'
    plpy.execute("""
                 DROP TABLE IF EXISTS {tbl_name};
                 CREATE {temp_str} TABLE {tbl_name} ({header})
                 """.format(tbl_name=tbl_name,
                            temp_str=temp_str,
                            header=header_with_type_str))
    data = []
    for i, r in enumerate(X, 1):
        data.append("({id}, '{{{val}}}')"
                    .format(id=i, val=','.join(map(str, r))))
    data = ','.join(data)
    plpy.execute("""
                 INSERT INTO {tbl_name}({header}) VALUES
                 {data}""".format(data=data,
                                  header=header_str,
                                  tbl_name=tbl_name))
    return tbl_name


class PolyKernel(object):
    """docstring for PolyKernel"""
    def __init__(self, degree=2, coef0=1, n_components=100,
                 random_state=1, random_weights=None):
        self.kernel_func = 'poly'
        self.degree = degree
        self.coef0 = coef0
        self.n_components = n_components
        self.random_state = random_state
        self.rd_weights = random_weights
        if self.rd_weights is not None:
            nf = num_features(self.rd_weights, 'val')
            assert(self.n_components*self.degree==nf)

    def saveAsText(self):
        return ','.join([str(self.degree), str(self.coef0),
                        str(self.n_components), self.rd_weights])

    @classmethod
    def loadFromText(cls, text):
        degree, coef0, n_components, rd_weights = text.split(',')
        return cls(degree=int(degree),
                   coef0=float(coef0),
                   n_components=int(n_components),
                   random_weights=rd_weights)

    @property
    def kernel_params(self):
        return ('degree={degree}, coef0={coef0}, n_components={n_components}'
                .format(degree=self.degree, coef0=self.coef0,
                        n_components=self.n_components))

    def fit(self, schema_madlib, n_features, kernel_params=''):

        params_default = {
            'degree': self.degree,
            'n_components': self.n_components,
            'coef0': self.coef0}

        params_types = {
            'degree': int,
            'n_components': int,
            'coef0': float}

        params_vals = extract_keyvalue_params(kernel_params,
                                              params_types,
                                              params_default)
        self.degree = params_vals['degree']
        self.coef0 = params_vals['coef0']
        self.n_components = params_vals['n_components']

        rd_state = np.random.RandomState(self.random_state)
        # uniform in [-1, 1]
        rd_weights_ = rd_state.choice([-1, 1], (n_features,
                              self.degree*self.n_components))
        self.rd_weights = _create_mat(rd_weights_,
                                      unique_string(desp='random_weights'))

    def transform(self, schema_madlib, source_table, independent_varname,
                  dependent_varname=None, grouping_col=None, id_col=None,
                  transformed_name='poly_transformed'):
        if not self.rd_weights:
            return self

        self.original_table = dict(source_table=source_table,
                                   independent_varname=independent_varname,
                                   dependent_varname=dependent_varname)

        grouping_col = ("NULL::integer as grouping_col"
                        if not grouping_col
                        else "{0}").format(grouping_col)

        dependent_varname = ("NULL::integer"
                             if not dependent_varname
                             else "{0}").format(dependent_varname)

        id_col = ("NULL::integer as id_col"
                  if not id_col
                  else "{0}").format(id_col)

        # copy data to the temporary table with id column
        # id_col is different from index_col
        # id_col is unique and, if any, is from the original table
        # index_col is generated randomly
        # needs to be sequential for madlib.matrix_mult to work
        source_with_id = unique_string(desp='source_copied')
        features_col = unique_string(desp='features_col')
        target_col = unique_string(desp='target_col')
        index_col = unique_string(desp='index_col')
        run_sql = """
            select setseed(0.5);
            drop table if exists {source_with_id};
            create temp table {source_with_id} as
                select
                    row_number() over (order by random()) as {index_col},
                    {dependent_varname} as {target_col},
                    {independent_varname} as {features_col},
                    {id_col},
                    {grouping_col}
                from {source_table}
        """.format(source_table=source_table,
                   source_with_id=source_with_id,
                   id_col=id_col,
                   index_col=index_col,
                   dependent_varname=dependent_varname,
                   independent_varname=independent_varname,
                   grouping_col=grouping_col,
                   target_col=target_col, features_col=features_col)
        plpy.execute(run_sql)
        source_table = source_with_id
        dependent_varname = target_col
        independent_varname = features_col

        temp_mult = unique_string(desp='temp_mult')
        # X = X * weights
        run_sql = """
            drop table if exists {temp_mult};
            select {schema_madlib}.matrix_mult(
                          '{source_table}',
                          'row={index_col}, val={independent_varname}',
                          '{rd_weights}',
                          'row=id, val=val',
                          '{temp_mult}',
                          'row={index_col}, val={independent_varname}');
        """.format(temp_mult=temp_mult,
                   schema_madlib=schema_madlib,
                   source_table=source_table,
                   rd_weights=self.rd_weights,
                   index_col=index_col,
                   independent_varname=independent_varname)
        plpy.execute(run_sql)

        temp_add = unique_string(desp='temp_add')
        addon = sqrt(self.coef0)
        run_sql = """
            drop table if exists {temp_add};
            create temp table {temp_add} as
                select
                    {index_col},
                    {schema_madlib}.array_scalar_add(
                            {independent_varname}::float[],
                            {addon}::float) as {independent_varname}
                from {temp_mult}
        """.format(index_col=index_col,
                   schema_madlib=schema_madlib,
                   independent_varname=independent_varname,
                   temp_add=temp_add,
                   temp_mult=temp_mult,
                   addon=addon)
        plpy.execute(run_sql)

        r, D = self.degree, self.n_components
        _band_matrix = np.array(list(chain.from_iterable(
                        repeat(x,r) for x in np.eye(D)))).reshape(r*D,D)
        _band_matrix = _create_mat(_band_matrix,
                                   unique_string(desp='band_matrix'),
                                   temporary=True)

        # X = X * band_matrix
        run_sql = """
            drop table if exists {temp_mult};
            select {schema_madlib}.matrix_mult(
                          '{temp_add}',
                          'row={index_col}, val={independent_varname}',
                          '{band_matrix}',
                          'row=id, val=val',
                          '{temp_mult}',
                          'row={index_col}, val={independent_varname}');
        """.format(temp_mult=temp_mult,
                   schema_madlib=schema_madlib,
                   temp_add=temp_add,
                   band_matrix=_band_matrix,
                   index_col=index_col,
                   independent_varname=independent_varname)
        plpy.execute(run_sql)

        transformed = unique_string(desp=transformed_name)

        # X = multiplier * X
        multiplier = 1 / np.sqrt(self.n_components)
        run_sql = """
            drop table if exists {transformed};
            create temp table {transformed} as
                select
                    {index_col},
                    {schema_madlib}.array_scalar_mult(
                        q.{independent_varname}::float[],
                        {multiplier}::float) as {independent_varname},
                    {dependent_varname},
                    {id_col},
                    {grouping_col}
                from {temp_mult} q join {source_table} s using ({index_col})
        """.format(index_col=index_col,
                   id_col=id_col,
                   dependent_varname=dependent_varname,
                   schema_madlib=schema_madlib,
                   independent_varname=independent_varname,
                   multiplier=multiplier,
                   grouping_col=grouping_col,
                   transformed=transformed,
                   source_table=source_table,
                   temp_mult=temp_mult)
        plpy.execute(run_sql)
        # clear table generated from matrix mult
        plpy.execute("drop table {0};".format(temp_mult))
        self.transformed_table = dict(index_col=index_col,
                                      source_table=transformed,
                                      dependent_varname=dependent_varname,
                                      independent_varname=independent_varname)
        return self


class GaussianKernelBase(object):

    """docstring for gaussianKernel"""

    def __init__(self, schema_madlib, gamma, n_components, random_state,
                 random_weights, random_offset, id_col, val_col,
                 orig_data, **kwargs):
        self.kernel_func = 'gaussian'
        self.gamma = gamma
        self.n_components = n_components
        # int32 seed used by boost::minstd_rand
        self.random_state = random_state
        # random operators
        self.rd_weights = random_weights
        self.rd_offset = random_offset
        # val column in random operators
        self.rd_val = val_col
        # id column in random operators
        self.rd_id = id_col
        self.transformed_table = dict()
        self.original_table = dict()
        # indicate whether rd_weights and rd_offset is view or table
        # store the original data table name if they are view
        # None if they are table
        self.orig_data = orig_data
        self.schema_madlib = schema_madlib
        if self.rd_offset is not None:
            self.n_components = num_features(self.rd_offset, self.rd_val)

    def _random_weights(self, row_dim, col_dim, rd_id, rd_val):
        rd_weights = unique_string(desp='random_weights')
        sigma = sqrt(2 * self.gamma)
        plpy.execute("""
            drop table if exists {rd_weights};
            select {self.schema_madlib}.matrix_random(
                    {row_dim}, {col_dim},
                    'mu=0, sigma={sigma}, seed={self.random_state}',
                    'normal',
                    '{rd_weights}','row={rd_id}, val={rd_val}');
        """.format(**locals()))
        return rd_weights

    def _random_offsets(self, row_dim, col_dim, rd_id, rd_val):
        rd_offset = unique_string(desp='random_offsets')
        max_ = 2 * pi
        plpy.execute("""
            drop table if exists {rd_offset};
            select {self.schema_madlib}.matrix_random(
                    {row_dim}, {col_dim},
                    'min=0, max={max_}, seed={self.random_state}',
                    'uniform',
                    '{rd_offset}','row={rd_id}, val={rd_val}');
        """.format(**locals()))
        return rd_offset

    def clear(self):
        data_type = 'view' if self.orig_data else 'table'
        if self.rd_weights:
            plpy.execute("drop {data_type} if exists {data};".format(
                         data=self.rd_weights,
                         data_type=data_type))
        if self.rd_offset:
            plpy.execute("drop {data_type} if exists {data};".format(
                         data=self.rd_offset,
                         data_type=data_type))

    def __del__(self):
        self.clear()

    def save_as(self, name):
        if self.orig_data:
            plpy.warning("Gaussian Kernel Warning: no need to save."
                         "Original data table exists: {0}".
                         format(self.orig_data))
            return

        run_sql = """
            create table {name} as
                select
                        {self.rd_id} as id, {self.rd_val} as val,
                        'offsets' as desp
                from {self.rd_offset}
                union
                select
                        {self.rd_id} as id, {self.rd_val} as val,
                        'weights' as desp
                from {self.rd_weights}
        """.format(**locals())
        plpy.execute(run_sql)

    @classmethod
    def parse_params(cls, kernel_params='', n_features=10):
        params_default = {
            'in_memory': 1,
            'gamma': 1 / n_features,
            'random_state': 1,
            'n_components': 2 * n_features}
        params_types = {
            'in_memory': int,
            'gamma': float,
            'random_state': int,
            'n_components': int}
        return extract_keyvalue_params(kernel_params,
                                       params_types,
                                       params_default)

    @classmethod
    def create(cls, schema_madlib, n_features, kernel_params):
        params = cls.parse_params(kernel_params, n_features)
        in_memory = params.pop('in_memory', True)
        # according to the 1gb limit on each entry of the table
        n_elems = params['n_components'] * n_features
        if in_memory and n_elems <= 1e8:
            return GaussianKernelInMemory(schema_madlib, **params)
        else:
            return GaussianKernel(schema_madlib, **params)

    @classmethod
    def load_from(cls, schema_madlib, data, kernel_params=''):
        rd_weights = unique_string(desp='random_weights')
        rd_offset = unique_string(desp='random_offsets')
        rd_val = unique_string(desp='val')
        rd_id = unique_string(desp='id')
        plpy.execute("""
                drop view if exists {rd_weights};
                create temp view {rd_weights} as
                    select id as {rd_id}, val as {rd_val} from {data}
                    where desp = 'weights';

                drop view if exists {rd_offset};
                create temp view {rd_offset} as
                    select id as {rd_id}, val as {rd_val} from {data}
                    where desp = 'offsets';
                     """.format(**locals()))
        params = cls.parse_params(kernel_params)
        in_memory = params.pop('in_memory', True)
        if in_memory:
            return GaussianKernelInMemory(schema_madlib,
                                          random_weights=rd_weights,
                                          random_offset=rd_offset,
                                          id_col=rd_id, val_col=rd_val,
                                          orig_data=data, **params)
        else:
            return GaussianKernel(schema_madlib,
                                  random_weights=rd_weights,
                                  random_offset=rd_offset,
                                  id_col=rd_id, val_col=rd_val,
                                  orig_data=data, **params)


class GaussianKernel(GaussianKernelBase):

    """docstring for gaussianKernel"""

    def __init__(self, schema_madlib, gamma=1, n_components=100,
                 random_state=1, random_weights=None,
                 random_offset=None, id_col=None, val_col=None,
                 orig_data=None, **kwargs):
        params = locals()
        params.pop('self')
        super(GaussianKernel, self).__init__(**params)

    @property
    def kernel_params(self):
        return ('gamma={gamma}, n_components={n_components},'
                'random_state={random_state}, in_memory=0'
                .format(gamma=self.gamma,
                        n_components=self.n_components,
                        random_state=self.random_state))

    def fit(self, n_features):
        self.clear()
        self.orig_data = None
        self.rd_val = unique_string(desp='val')
        self.rd_id = unique_string(desp='id')
        self.rd_weights = self._random_weights(n_features, self.n_components,
                                               self.rd_id, self.rd_val)
        self.rd_offset = self._random_offsets(1, self.n_components,
                                              self.rd_id, self.rd_val)
        return self

    def transform(self, source_table, independent_varname,
                  dependent_varname=None, grouping_col=None, id_col=None,
                  transformed_name='gaussian_transformed'):
        if not self.rd_offset or not self.rd_weights:
            return self

        self.original_table = dict(source_table=source_table,
                                   independent_varname=independent_varname,
                                   dependent_varname=dependent_varname)

        schema_madlib = self.schema_madlib

        def _verify(x, s):
            null_str = "NULL::integer"
            if x:
                return str(x)
            else:
                return null_str + " as " + s if s else null_str

        grouping_col = _verify(grouping_col, unique_string('grp_col'))
        dependent_varname = _verify(dependent_varname, '')
        id_col = _verify(id_col, unique_string('id_col'))

        # copy data to the temporary table with id column
        # id_col is different from index_col
        # id_col is unique and, if any, is from the original table
        # index_col is generated randomly
        # needs to be sequential for madlib.matrix_mult to work
        source_with_id = unique_string(desp='source_copied')
        features_col = unique_string(desp='features_col')
        target_col = unique_string(desp='target_col')
        index_col = unique_string(desp='index_col')
        run_sql = """
            select setseed(0.5);
            drop table if exists {source_with_id};
            create temp table {source_with_id} as
                select
                    row_number() over (order by random()) as {index_col},
                    {dependent_varname} as {target_col},
                    {independent_varname} as {features_col},
                    {id_col},
                    {grouping_col}
                from {source_table}
        """.format(**locals())
        plpy.execute(run_sql)
        source_table = source_with_id
        dependent_varname = target_col
        independent_varname = features_col

        temp_transformed = unique_string(desp='temp_transformed')
        # X = X * weights
        run_sql = """
            drop table if exists {temp_transformed};
            select {schema_madlib}.matrix_mult(
                          '{source_table}',
                          'row={index_col}, val={independent_varname}',
                          '{self.rd_weights}',
                          'row={self.rd_id}, val={self.rd_val}',
                          '{temp_transformed}',
                          'row={index_col}, val={independent_varname}');
        """.format(**locals())
        plpy.execute(run_sql)

        transformed = unique_string(desp=transformed_name)

        # rd_offset is a vector of n_components elements
        # which will fit in memory most of the time. Plus,
        # putting rd_offset in memory makes broadcasting it to
        # segments more efficiently
        rd_offset_vals = plpy.execute("""
                      select {rd_val} as val from {rd_offset}
                      """.format(rd_val=self.rd_val,
                                 rd_offset=self.rd_offset))[0]['val']

        # X = a * cos (X + b)
        multiplier = sqrt(2. / self.n_components)
        run_sql = """
            drop table if exists {transformed};
            create temp table {transformed} as
                select
                    {index_col},
                    {schema_madlib}.array_scalar_mult(
                        {schema_madlib}.array_cos(
                            q.{independent_varname}::float[])::float[],
                        {multiplier}::float) as {independent_varname},
                    {dependent_varname},
                    {id_col},
                    {grouping_col}
                from (
                    select
                        x.{index_col},
                        {schema_madlib}.array_add(
                            x.{independent_varname}::float[],
                            $1) as {independent_varname}
                    from {temp_transformed} as x
                ) q join {source_table} s using ({index_col})
        """.format(**locals())
        plpy.execute(plpy.prepare(run_sql, ['float[]']), [rd_offset_vals])
        # clear table generated from matrix mult
        plpy.execute("drop table if exists " + temp_transformed)
        self.transformed_table = dict(index_col=index_col,
                                      source_table=transformed,
                                      dependent_varname=dependent_varname,
                                      independent_varname=independent_varname)
        return self


class GaussianKernelInMemory(GaussianKernelBase):

    """docstring for gaussianKernel"""

    def __init__(self, schema_madlib, gamma=1, n_components=100,
                 random_state=1, random_weights=None,
                 random_offset=None, id_col=None,
                 val_col=None, orig_data=None, **kwargs):
        params = locals()
        params.pop('self')
        super(GaussianKernelInMemory, self).__init__(**params)

    @property
    def kernel_params(self):
        return ('gamma={gamma}, n_components={n_components},'
                'random_state={random_state}, in_memory=1'
                .format(gamma=self.gamma,
                        n_components=self.n_components,
                        random_state=self.random_state))

    def fit(self, n_features):
        self.clear()
        self.orig_data = None
        self.rd_val = unique_string(desp='val')
        self.rd_id = unique_string(desp='id')
        self.rd_weights = self._random_weights(1, n_features * self.n_components,
                                               self.rd_id, self.rd_val)
        self.rd_offset = self._random_offsets(1, self.n_components,
                                              self.rd_id, self.rd_val)
        return self

    def transform(self, source_table, independent_varname,
                  dependent_varname=None, grouping_col=None, id_col=None,
                  transformed_name='gaussian_transformed'):
        if not self.rd_offset or not self.rd_weights:
            return self

        self.original_table = dict(source_table=source_table,
                                   independent_varname=independent_varname,
                                   dependent_varname=dependent_varname)

        schema_madlib = self.schema_madlib

        def _verify(x, s):
            null_str = "NULL::integer"
            if x:
                return str(x)
            else:
                return null_str + " as " + s if s else null_str

        grouping_col = _verify(grouping_col, unique_string('grp_col'))
        dependent_varname = _verify(dependent_varname, '')
        id_col = _verify(id_col, unique_string('id_col'))

        features_col = unique_string(desp='features_col')
        target_col = unique_string(desp='target_col')
        transformed = unique_string(desp=transformed_name)

        # X <- a * cos (X*C + b)
        multiplier = sqrt(2. / self.n_components)
        run_sql = """
            drop table if exists {transformed};
            create temp table {transformed} as
                select
                    {schema_madlib}.array_scalar_mult(
                        {schema_madlib}.array_cos(
                            {schema_madlib}.array_add(
                                {schema_madlib}.__matrix_vec_mult_in_mem(
                                    q.{features_col}::float[],
                                    rw.{self.rd_val}::float[]
                                )::float[],
                                ro.{self.rd_val}::float[]
                            )::float[]
                        )::float[],
                        {multiplier}::float
                    ) as {features_col},
                    q.{target_col} as {target_col},
                    {id_col},
                    {grouping_col}
                from (
                    select
                        {dependent_varname} as {target_col},
                        {independent_varname} as {features_col},
                        {id_col},
                        {grouping_col}
                    from {source_table}
                ) q
                cross join (select {self.rd_val} from {self.rd_weights}) as rw
                cross join (select {self.rd_val} from {self.rd_offset}) as ro
        """.format(**locals())
        plpy.execute(run_sql)
        self.transformed_table = dict(source_table=transformed,
                                      dependent_varname=target_col,
                                      independent_varname=features_col)
        return self


def create_kernel(schema_madlib, n_features, kernel_func, kernel_params):
    if kernel_func == 'linear':
        return None
    elif kernel_func == 'gaussian':
        return GaussianKernelBase.create(schema_madlib,
                                         n_features,
                                         kernel_params)


def load_kernel(schema_madlib, data, kernel_func, kernel_params):
    if kernel_func == 'linear':
        return None
    elif kernel_func == 'gaussian':
        return GaussianKernelBase.load_from(schema_madlib, data, kernel_params)
